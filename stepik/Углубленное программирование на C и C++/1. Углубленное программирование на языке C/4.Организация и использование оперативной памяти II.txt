   // указатели на массивы и массивы указателей
   int  k[3][5];
   int (*pk)[5];  // указатель на массив int[5]
   int *p[5];     // массив указателей (int*)[5]
   
   // примеры использования (все - допустимы)
   pk       = k;  // аналогично: pk = &k[0]
   pk[0][0] = 1;  // аналогично: k[0][0] = 1;
   *pk[0]   = 2;  // аналогично: k[0][0] = 2;
   **pk     = 3;  // аналогично: k[0][0] = 3;
   
  - Использование ключевого слова restrict допустимо строго в отношении указателей и ...
      * расширяет возможности компилятора по оптимизации некоторых видов кода путем поиска сокрашения методов вычислений
      * озночает, что указатель - единственное(других нет) исходного (первоначальное) средство доступа к соответствующему объекту
   
  - В отсутствии квалификатор restrict компилятор вынужден прибегать к "пессимистичной" стратегии оптимизации
  - Квалификатор restrict широко применяется в отношении формальных параметров функций стандартной библиотеки языка С. Например:
      void* memcpy(void *restrict s1, const void *restrict s2, size_t n);
      

  Существование в языке объектов вида T (*pt)[M] открывает возможность встраивания информации о длине строк массива в тип данных и определения функций с прототипами вида:
   * void foo(T a[][M], size_t N);
   * void foo(T (*a)[M], size_t N); // комплект [] трактуется как указатель
   
   Массивы переменной длины: создаются на стеку, но их размер становится известен во время выполнения
   
   int foo(size_t rows, size_t cols, double a[row][cols]);
   int foo(size_t, size_t, double a[*][*]) // имена опущены
   
   int bar() {
      int n = 3, m = 4;
      int var[n][m]; // массив, как локальная переменная
      ...
   }
   
   Упаковака переменных составных типов:
   * Для структур данных актуален также не характерный для массивов и скаляров вопрос упаковки данных, обусловленный наличием у элементов структур индивидуальных характеристик выравнивания.
   * Проблема упаковки структур заключается в том, что смежные(перечисленные подряд) элементы часто физически не "примыкают" друг к другу в памяти
   
   Например (для x86):
      typedef struct {
         int      id;         //  4 байта
         char     name[15];   // 15 байт
         /*  лакуна - 1 байт выравнивания */
         double   amount;     //  8 байт
         _Bool    active;     //  1 байт
         /*  лакуна - 3 байта выравнивания */
      } account;              // 28 байт(не 32 байта!)
      
   Реорганизация структур данных:
   рекомендации
   * Реорганизация структур для повышения эффективности использование кэш-памяти должна идти по 2 направлениям:
      - декомпозиция тяжеловестных("божественных") структур на более мелкие, узкоспециализированные структуры, которые при решении конкретной  задачи используются полностью, либо не используются вообще;
      - устранения в структурах лакун, обусловленных характеристиками выравнивания типов их элементов
      
   * При прочих равных условиях крайне желательно:
      - переносить наиболее востребованные элементы структуры к ее началу (при загрузке в кэш-память такие элементы структуры могут становиться "критическими словами", доступ к которым должен быть самым быстрым);
      - обходить структуру в порядке определения элементов, если иное не требуется в задаче или прочими обстоятельствами
      
      typedef struct {
         int      id;         //  4 байта
         char     name[15];   // 15 байт
         _Bool    active;     //  1 байт
         double   amount;     //  8 байт
      } account;              // 28 байт
      
      Недостатки реорганизации:
         - снижения удобства чтения и сопровождение исходного кода
         - риск размещения совместно используемых элементов(напр. длины вектора и адреса его начально элемента) на разных линиях кэш-памяти
       
      Основная альтерантива реорганизации - замена стихийно выбранных типов данных наиболее адекватными по размеру, вплоть до использования битовых полей данных
      

   КЭШ-ПАМЯТЬ в архитектуре современных ЭВМ
   *  Проблема - отставание системной шины[и модулей оперативной памяти (DRAM)] от ядра ЦП по внутренней частоте; простой ЦП
   *  Решение - включение в архитектуру небольших модулей сверхоперативной памяти (SRAM), полностью контролируемой ЦП.
   *  Условия эффективности - локальность данных и кода в пространстве-времени
   
   ЧТО ДЕЛАТЬ?
   *  Обеспечивать локальность данных и команд в пространстве и времени:
      * совместно хранить совместно используемые данные или команды;
      * не нарушать эмпирические правила написания эффективного кода.
   * Обеспечивать эффективность загрузке общей (L2, L3) и раздельной кэш-памяти данных (L1d) и команд (L1i):
      * полагаться на оптимизирующие возможности компилятора;
      * помогать компилятору в процессе написания кода.
   * Знать основые организации аппаратного обеспечения.
   * Экспериментировать!
   
   Эффективный обход двумерных массивов
   * Простейшим способом повышения эффективности работы с двумерным массивом является отказ от его обхода по столбцам в пользу обхода по строкам:
      * для массивов, объем которых превышает размер (выделенной процессу) кэш памяти данных самого верхнего уровня(напр. L2d), время инициализации по строкам приблизительно втрое меньше времени инициализации по столбцам вне зависимости от того, ведется ли запись в кэш-память или в оперативную память в обход нее (У.Дреппер, 2007)
   * Дальнейшая оптимизация может быть связана с анализом и переработкой решаемой задачи в целях снижения частоты кэш-промахов или использования векторных инструкций процессора (SIMD - Single Instruction, Multiple Data)
   
   Почему оптимизиация работы с кэш-памятью того стоит?
   * Несложная трансофрмация вычислительных фрагментов кода позволяет добиться серьезного роста скорости выполнения:
      разбиения на квадрат (square blocking) и пр.
   * Причина - высокая "стоимость" кэш-промахов:
   
   Время доступа, такты ЦП
   Регистровая память: 1
   Кэш-память 1-ого уровня: 3
   Кэш-память 2-ого уровня: 14
   Оперативная память: 240
   
   Что еще можно оптимизировать?
      * Предсказание переходов:
         * устранение ветвлений
         * равертывание (линеаризация) циклов;
         * встраивание функций (методов) и пр.
      * Критические секции:
         * устанение цепочек зависимости для внеочередного исполнения инструкций;
         * использование поразрядных операций, INC(++), DEC(--), векторизация (SIMD) и т.д.
      * Обращение к памяти:
         * выполнение потоковых операций
         * выравнивание и упаковка данных и пр.
   
   
   
   